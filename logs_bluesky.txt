================================================================================
LOADING BLUESKY DATASET
================================================================================

Loading dataset from datasets/bluesky/personas.pkl...
Loaded 44,846 posts
Filtered to 35,914 training posts
Sampled 5,000 posts
Dataset columns: ['user_id', 'username', 'persona', 'message', 'reply_to', 'training']
Text column: message

Inferring metadata (sentiment, topics, style, polarization)...
This may take a few minutes...

Inferring metadata for 5000 texts...
  Processed 1000/5000 texts
  Processed 2000/5000 texts
  Processed 3000/5000 texts
  Processed 4000/5000 texts
  Processed 5000/5000 texts
Completed metadata inference for 5000 texts
Saved metadata cache to outputs/metadata_cache/bluesky_metadata.pkl

Final dataset: 5000 posts with metadata

================================================================================
INITIALIZING LLM CLIENT
================================================================================

Provider: openai
Model: gpt-4o-mini


================================================================================
RUNNING PROMPT STYLE COMPARISON
================================================================================

Dataset: bluesky
Dataset size: 5000 posts
Pool size: 100
Recommendations per trial: 10
Trials per style: 100
Prompt styles: general, popular, engaging, informative, controversial, neutral


[1/6] Testing prompt style: GENERAL
================================================================================
  Trial 1/100 ✓
  Trial 2/100 ✓
  Trial 3/100 ✓
  Trial 4/100 ✓
  Trial 5/100 ✓
  Trial 6/100 ✓
  Trial 7/100 ✓
  Trial 8/100 ✓
  Trial 9/100 ✓
  Trial 10/100 ✓
  Trial 11/100 ✓
  Trial 12/100 ✓
  Trial 13/100 ✓
  Trial 14/100 ✓
  Trial 15/100 ✓
  Trial 16/100 ✓
  Trial 17/100 ✓
  Trial 18/100 ✓
  Trial 19/100 ✓
  Trial 20/100 ✓
  Trial 21/100 ✓
  Trial 22/100 ✓
  Trial 23/100 ✓
  Trial 24/100 ✓
  Trial 25/100 ✓
  Trial 26/100 ✓
  Trial 27/100 ✓
  Trial 28/100 ✓
  Trial 29/100 ✓
  Trial 30/100 ✓
  Trial 31/100 ✓
  Trial 32/100 ✓
  Trial 33/100 ✓
  Trial 34/100 ✓
  Trial 35/100 ✓
  Trial 36/100 ✓
  Trial 37/100 ✓
  Trial 38/100 ✓
  Trial 39/100 ✓
  Trial 40/100 ✓
  Trial 41/100 ✓
  Trial 42/100 ✓
  Trial 43/100 ✓
  Trial 44/100 ✓
  Trial 45/100 ✓
  Trial 46/100 ✓
  Trial 47/100 ✓
  Trial 48/100 ✓
  Trial 49/100 ✓
  Trial 50/100 ✓
  Trial 51/100 ✓
  Trial 52/100 ✓
  Trial 53/100 ✓
  Trial 54/100 ✓
  Trial 55/100 ✓
  Trial 56/100 ✓
  Trial 57/100 ✓
  Trial 58/100 ✓
  Trial 59/100 ✓
  Trial 60/100 ✓
  Trial 61/100 ✓
  Trial 62/100 ✓
  Trial 63/100 ✓
  Trial 64/100 ✓
  Trial 65/100 ✓
  Trial 66/100 ✓
  Trial 67/100 ✓
  Trial 68/100 ✓
  Trial 69/100 ✓
  Trial 70/100 ✓
  Trial 71/100 ✓
  Trial 72/100 ✓
  Trial 73/100 ✓
  Trial 74/100 ✓
  Trial 75/100 ✓
  Trial 76/100 ✓
  Trial 77/100 ✓
  Trial 78/100 ✓
  Trial 79/100 ✓
  Trial 80/100 ✓
  Trial 81/100 ✓
  Trial 82/100 ✓
  Trial 83/100 ✓
  Trial 84/100 ✓
  Trial 85/100 ✓
  Trial 86/100 ✓
  Trial 87/100 ✓
  Trial 88/100 ✓
  Trial 89/100 ✓
  Trial 90/100 ✓
  Trial 91/100 ✓
  Trial 92/100 ✓
  Trial 93/100 ✓
  Trial 94/100 ✓
  Trial 95/100 ✓
  Trial 96/100 ✓
  Trial 97/100 ✓
  Trial 98/100 ✓
  Trial 99/100 ✓
  Trial 100/100 ✓
  Completed 100 trials for general

[2/6] Testing prompt style: POPULAR
================================================================================
  Trial 1/100 ✓
  Trial 2/100 ✓
  Trial 3/100 ✓
  Trial 4/100 ✓
  Trial 5/100 ✓
  Trial 6/100 ✓
  Trial 7/100 ✓
  Trial 8/100 ✓
  Trial 9/100 ✓
  Trial 10/100 ✓
  Trial 11/100 Traceback (most recent call last):
  File "/home/nicpag/data/llm-recommendation-bias-analysis/run_experiment.py", line 357, in <module>
    main()
  File "/home/nicpag/data/llm-recommendation-bias-analysis/run_experiment.py", line 293, in main
    rec = run_single_recommendation(llm_client, pool, K, style, text_col)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nicpag/data/llm-recommendation-bias-analysis/run_experiment.py", line 147, in run_single_recommendation
    response = llm_client.generate(prompt, temperature=0.3)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nicpag/data/llm-recommendation-bias-analysis/utils/llm_client.py", line 108, in generate
    response = self.client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nicpag/data/conda/envs/recsys_env/lib/python3.11/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/nicpag/data/conda/envs/recsys_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1189, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/nicpag/data/conda/envs/recsys_env/lib/python3.11/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nicpag/data/conda/envs/recsys_env/lib/python3.11/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 500
